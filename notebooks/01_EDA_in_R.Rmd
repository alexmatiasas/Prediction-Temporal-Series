---
title: "EDA - Energy Consumption and Weather Data"
author: "Manuel Alejandro MatÃ­as Astorga"
output:
  html_document:
    toc: true
    toc_depth: 3
    toc_float: true
    number_sections: false
---

This notebook performs an exploratory data analysis (EDA) on the [hourly energy demand, generation, pricing, and weather dataset](https://www.kaggle.com/datasets/nicholasjhana/energy-consumption-generation-prices-and-weather).

> This dataset contains four years of hourly data on electricity consumption, generation, prices, and weather conditions in Spain. Energy data was retrieved from ENTSOE (a public TSO portal), pricing data from Red ElÃ©ctrica EspaÃ±ola, and weather data (for the five largest cities in Spain) was originally obtained via the OpenWeather API and made public by the dataset author.

The main goals of this EDA are:

- To understand the structure and quality of the datasets.
- To detect missing or inconsistent values.
- To identify temporal patterns in energy usage.
- To prepare the data for feature engineering and modeling.

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning = FALSE, message = FALSE)        # Set global options for knitr
options(scipen = 999)  # avoid scientific notation
```

### ğŸ“¦ Load libraries

```{r libraries}
# Load necessary packages for data wrangling and visualization
library(tidyverse)    # Core data manipulation tools
library(lubridate)    # Date-time parsing and extraction
library(skimr)        # Data summary and structure
library(janitor)      # Clean column names
library(ggplot2)      # Data visualization
library(ggthemes)     # Visualization themes
library(viridis)      # Color palettes
library(ggcorrplot)   # Correlation matrix visualization
```

### ğŸ“ Load data

```{r load_data}
# Read raw CSV files (energy and weather) from 'data/raw' relative to notebook location
energy <- read_csv("../data/raw/energy_dataset.csv")
weather <- read_csv("../data/raw/weather_features.csv")
```

### ğŸ§¹ Clean column names

```{r convert-columns}
# Convert column names to snake_case format
energy <- energy %>% clean_names()
weather <- weather %>% clean_names()
```

## ğŸ§¹ 1. Data Overview & Structure

To begin the analysis, we perform a quick structural inspection using `glimpse()` and a detailed statistical summary with `skim()` for both datasets: **energy** and **weather**.

### ğŸ” 1.1 Glimpse: See Columns and Data Types

#### ğŸ” 1.1.1 Glimpse: Energy Dataset

```{r structure-energy}
# Display the structure of the energy dataset
glimpse(energy)
```

The *energy* dataset contains 35,064 hourly records and 29 columns, which include:

- Timestamps (`time`)
- Energy generation by source (e.g., `generation_biomass`, `generation_solar`)
- Forecast and actual values for energy consumption (`total_load_forecast`, `total_load_actual`)
- Pricing variables (`price_day_ahead`, `price_actual`)

The data appears to span from *2014-12-31* to *2018-12-31* with 1-hour intervals.

#### ğŸ” 1.1.2 Glimpse: Weather Dataset

```{r structure-weather}
# Display the structure of the weather dataset
glimpse(weather)
```

The weather dataset has 178,396 rows and 17 columns, including:

- Timestamps (`dt_iso`)
- Weather observations for major Spanish cities (`city_name`)
- Variables such as `temp`, `humidity`, `wind_speed`, `pressure`, and `weather_description`

This dataset also has a datetime range matching the energy dataset, which facilitates temporal merging.

### ğŸ“Š 1.2 Skim: Summary Statistics

#### âš¡ 1.2.1 Skim: Energy Dataset

```{r skim-summary-energy}
# Display summary statistics for the energy dataset
skim(energy)
```

- Most columns are numeric (`dbl`), with one datetime column (`POSIXct`) and two logical columns that represent completely missing data (`NA` only).
- Missing data is generally very low (â‰¤ 0.1%) across most variables, except for two:
  - `generation_hydro_pumped_storage_aggregated`
  - `forecast_wind_offshore_eday_ahead`
These two were removed from the dataset due to having **100% missing values**.
- Some generation sources such as **coal-derived gas**, **oil shale**, and **geothermal** are recorded as zeros or missing throughout the entire time series â€” this might be expected depending on Spainâ€™s energy infrastructure.

#### ğŸŒ¦ï¸ 1.2.2 Skim:  Weather Dataset

```{r skim-summary-weather}
# Display summary statistics for the weather dataset
skim(weather)
```

- Weather data is well-structured with `no missing values` in any column.
- It includes:
  - Numeric weather conditions (`temp`, `pressure`, `wind_speed`, etc.)
  - Categorical weather types (`weather_main`, `weather_description`)
  - Identifiers and icons from the API (`weather_id`, `weather_icon`)

This dataset is well-suited for modeling, with consistent sampling and granularity.

### ğŸ“Œ 1.3 Conclusion of Initial Inspection

- Both datasets are **clean and well-structured**.
- We removed only two columns due to full missingness.
- The time coverage and granularity are compatible, making them ideal for feature engineering and merging.
- From this point forward, we can derive temporal features, visualize trends, and assess correlations.

Finally we treat our datasets based on out observations:

- We double-check for missing values and

```{r missing-values}
# Summarize missing values per variable in both datasets to assess data quality
# NA summary - Energy
energy %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "n_missing") %>%
  mutate(
    pct_missing = round(100 * n_missing / nrow(energy), 2)
  ) %>%
  arrange(desc(pct_missing))
# NA summary - Weather
weather %>%
  summarise(across(everything(), ~ sum(is.na(.)))) %>%
  pivot_longer(everything(), names_to = "variable", values_to = "n_missing") %>%
  mutate(
    pct_missing = round(100 * n_missing / nrow(weather), 2)
  ) %>%
  arrange(desc(pct_missing))
```

- remove columns with 100% missingness and

```{r eliminating-columns-with-100-percent-missing}
# Remove columns that contain 100% missing values and provide no useful information
energy <- energy %>%
  select(-any_of(c("generation_hydro_pumped_storage_aggregated",
                   "forecast_wind_offshore_eday_ahead")))
```

- rename time columns to `datetime` for consistency.

```{r rename-columns-datetime}
# Rename time columns to 'datetime' for consistency
energy <- energy %>%
  rename(datetime = time)
weather <- weather %>%
  rename(datetime = dt_iso)
```

and that's it! We are ready to merge the datasets.

## ğŸ” 2. Merging Datasets

Once we have cleaned the datasets, we can merge them based on the `datetime` column. This will allow us to analyze the relationship between **energy** consumption and **weather** conditions.

```{r merge}
combined <- left_join(energy, weather, by = "datetime")
```

We use `left_join()` to ensure that all records from the energy dataset are retained, even if there are no corresponding weather records.

> **Note**: Weather data includes observations from five major Spanish cities. Since the energy dataset is aggregated at the national level, no spatial distinction is made in this EDA. All weather records are merged and interpreted as representative of national conditions. In a future step, we could aggregate weather by hour (averaging across cities) or isolate individual cities if needed.

## ğŸ“Š 3. Exploratory Plots

In this section, we visualize major variables over time to understand trends, patterns, and potential anomalies. All plots are based on the `combined` dataset, which merges **weather** and **energy** information.

### ğŸ“ˆ 3.1 Energy Load: Forecast vs Actual

This plot shows the forecasted vs actual energy load over time. While the general trends match, we can spot some deviations, which may indicate model drift, unexpected events, or forecasting bias.

```{r plot-energy-load}
combined %>%
  select(datetime, total_load_forecast, total_load_actual) %>%
  pivot_longer(-datetime) %>%
  ggplot(aes(x = datetime, y = value, color = name)) +
  geom_line(alpha = 0.6) +
  labs(title = "Energy Load: Forecast vs Actual", y = "Load (MW)", x = "Time") +
  theme_minimal()
```

### ğŸŒ¤ï¸ 3.2 Weather Trends Over Time

We track the evolution of temperature, humidity, and wind speed. The periodic structure (particularly in temperature) suggests strong seasonality. Humidity and wind speed show more variability, potentially correlating with energy production in certain sources.

```{r plot-weather-trends}
combined %>%
  select(datetime, temp, wind_speed, humidity) %>%
  pivot_longer(-datetime) %>%
  ggplot(aes(x = datetime, y = value, color = name)) +
  geom_line(alpha = 0.5) +
  facet_wrap(~name, scales = "free_y") +
  labs(title = "Weather Variables Over Time", y = "Value", x = "Time") +
  theme_minimal()
```

### ğŸ“Š 3.3 Price Trends

This chart compares the day-ahead market price with the actual price. Large discrepancies may highlight forecast errors or market volatility. These trends are essential for assessing model accuracy and energy strategy.

```{r plot-prices}
combined %>%
  select(datetime, price_day_ahead, price_actual) %>%
  pivot_longer(-datetime) %>%
  ggplot(aes(x = datetime, y = value, color = name)) +
  geom_line(alpha = 0.6) +
  labs(title = "Electricity Prices: Day Ahead vs Actual", y = "â‚¬/MWh", x = "Time") +
  theme_minimal()
```

### ğŸ” 3.4 Energy Load - Sample Week

To better understand short-term fluctuations, we zoom into the first week of 2015. We observe clear daily cycles, indicating high periodicity and potential for time-series decomposition.

```{r plot-prices-zoom}
combined %>%
  filter(datetime >= as.POSIXct("2015-01-01"),
         datetime <= as.POSIXct("2015-01-07")) %>%
  ggplot(aes(x = datetime, y = total_load_actual)) +
  geom_line() +
  labs(title = "Energy Load - Sample Week", y = "MW", x = "Date") +
  theme_minimal()
```

## ğŸ“… 4. Temporal Patterns

This section analyzes temporal patterns in energy demand by extracting time-based features and visualizing their influence on consumption.

### ğŸ§© 4.1 Add Time Features

```{r add-time-features}
# Extract hour, weekday and month from datetime
combined <- combined %>%
  mutate(
    hour = hour(datetime),
    wday = wday(datetime, label = TRUE, abbr = TRUE),  # e.g., Mon, Tue
    month = month(datetime, label = TRUE, abbr = TRUE) # e.g., Jan, Feb
  )
```

### ğŸ• 4.2 Average Load by Hour

```{r avg-load-hour}
# Average actual load by hour of the day
combined %>%
  group_by(hour) %>%
  summarise(avg_load = mean(total_load_actual, na.rm = TRUE)) %>%
  ggplot(aes(x = hour, y = avg_load)) +
  geom_line(color = "steelblue", linewidth = 1) +
  labs(
    title = "Average Energy Load by Hour",
    x = "Hour of Day", y = "Average Load (MW)"
  ) +
  theme_minimal()
```

ğŸ’¡ **Insight**: This plot reveals the daily cycle of energy demand, typically with peaks in the morning and evening, and a drop at night.

### ğŸ“… 4.3 Load Distribution by Day of Week

```{r load-distribution-wday}
# Distribution of actual load by weekday
combined %>%
  mutate(wday = factor(wday, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"))) %>%
  ggplot(aes(x = wday, y = total_load_actual)) +
  geom_boxplot(fill = "skyblue", alpha = 0.6, outlier.color = "gray") +
  labs(
    title = "Energy Load Distribution by Weekday",
    x = "Day of Week", y = "Load (MW)"
  ) +
  theme_minimal()
```

ğŸ’¡ **Insight**: Boxplots show variability between weekdays and weekends. Useful to detect behavioral or industrial consumption patterns.

### ğŸ“† 4.4 Load Distribution by Month

```{r load-distribution-month}
# Average load per month across all years
combined %>%
  group_by(month) %>%
  summarise(avg_load = mean(total_load_actual, na.rm = TRUE)) %>%
  ggplot(aes(x = month, y = avg_load, group = 1)) +
  geom_line(color = "darkgreen", linewidth = 1) +
  geom_point(color = "darkgreen", size = 2) +
  labs(
    title = "Monthly Average Energy Load",
    x = "Month", y = "Average Load (MW)"
  ) +
  theme_minimal()
```

ğŸ’¡ **Insight**: This plot helps identify seasonal demand patterns. For example, summer or winter peaks could guide forecasting strategies.

## ğŸ“ˆ 5. Correlation Analysis

In this section, we explore the relationships between numeric features, particularly between weather conditions and energy load.

### ğŸ” 5.1 Why we do correlation analysis?

Correlation analysis helps us understand the relationships between numeric features in the dataset. This is useful for:

- Selecting relevant predictors for machine learning models.
- Detecting multicollinearity and removing redundant variables.
- Uncovering physical dependencies or seasonal behavior in energy demand.

In this notebook, we use **Pearson correlation**, which measures linear relationships. We also apply `drop_na()` to ensure the correlations are calculated on complete data only.

```{r correlation-matrix}
# Select only numeric columns and compute Pearson correlation
correlation_matrix <- combined %>%
  select(where(is.numeric)) %>%
  drop_na() %>%
  cor(method = "pearson")
```

### ğŸ” 5.2 Visualize Correlation Matrix

```{r plot-correlation-matrix}
# Plot correlation matrix using ggcorrplot
ggcorrplot(correlation_matrix, 
           method = "circle", 
           type = "lower", 
           lab = TRUE,
           lab_size = 2.5,
           colors = c("#6D9EC1", "white", "#E46767"),
           title = "Correlation Matrix (Numerical Features)",
           ggtheme = theme_minimal())
```

ğŸ’¡ **Note**: This global correlation matrix provides a technical overview of all numeric features. While useful to detect potential redundancies or collinearities, its density makes it hard to extract actionable insights.

We defer focused interpretation to the next section.

### ğŸ§  5.3 Correlation on Energy Load and Weather Variables

To better understand how energy consumption relates to weather, we isolated key variables and computed their pairwise Pearson correlations.

```{r correlation-energy-weather}
# Focus only on energy load and weather variables
subset_corr <- combined %>%
  select(total_load_actual, total_load_forecast, temp, humidity, wind_speed, pressure) %>%
  drop_na() %>%
  cor()

ggcorrplot(subset_corr, lab = TRUE, type = "lower", ggtheme = theme_minimal())
```

### ğŸ’¡ Key Insights

- ğŸ”´ `total_load_actual` and `total_load_forecast` are very strongly correlated (â‰ˆ 1), which confirms the forecastâ€™s high alignment with actual demand.
- ğŸ”µ `temp` and `humidity` exhibit a strong negative correlation (-0.574), reflecting the physical inverse relationship between air temperature and relative humidity.
- ğŸŸ¡ The relationship between energy demand (`total_load_actual`) and weather conditions is weak to moderate:
  - Temperature: 0.18 (weak positive)
  - Humidity: -0.25 (weak negative)
  - Wind speed: 0.13 (very weak positive)
- âšª `Pressure` is effectively uncorrelated with both energy demand and other variables (all correlations â‰ˆ 0).

These results suggest that while weather contributes to variations in energy usage, its linear influence is limited and possibly non-linear or confounded by other factors like time-of-day or city.

## ğŸ§  6. Insights & Next Steps

This exploratory analysis has revealed several key patterns in the energy demand dataset:

### ğŸ“Œ Key Insights

- **Strong correlation** between `total_load_actual` and `total_load_forecast` confirms the reliability of the forecasts provided.
- **Temperature shows moderate negative correlation with humidity**, hinting at potential seasonal effects.
- **Energy consumption patterns follow a clear daily cycle**, with peaks in the morning and evening, and lower demand at night.
- **Weekends show slightly lower energy demand**, which may reflect reduced industrial activity.
- **Seasonal variations** suggest that monthly factors should be considered when building predictive models.

### ğŸš€ Next Steps

- Engineer **lagged features** to capture temporal dependencies.
- Create **rolling averages** or **moving windows** for smoother time-series signals.
- Introduce **categorical encodings** (e.g., one-hot for weekdays/months).
- Prepare train-test split considering **time-based validation** (e.g., walk-forward).
- Begin modeling with baseline approaches (e.g., linear regression, ARIMA, or gradient boosting).

This EDA serves as a foundation to inform feature selection and modeling decisions in the next phase of this project.

*As a final result, we export our final `combined` dataset for future use.*

```{r export-combined}
# Create 'processed' folder if it doesn't exist
if (!dir.exists("../data/processed")) {
  dir.create("../data/processed", recursive = TRUE)
}
# Export combined cleaned dataset for use in Python
write_csv(combined, "../data/processed/combined_clean.csv")
```
