{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {},
   "source": [
    "# 📊 Baseline Modeling – Energy Consumption Forecast\n",
    "\n",
    "This notebook establishes baseline models for forecasting electricity consumption using the engineered dataset from previous steps.\n",
    "\n",
    "We will:\n",
    "- Load the processed feature matrix\n",
    "- Split the data chronologically into training and testing sets\n",
    "- Build simple baseline models (e.g., Naive, Mean)\n",
    "- Evaluate their performance using MAE, RMSE, and R²\n",
    "\n",
    "These baselines will serve as reference points to assess the performance of more advanced machine learning models in future notebooks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {},
   "source": [
    "## 🧰 0. Code: Setup + Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 📦 Import libraries\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 🔄 Load feature dataset\n",
    "df = pd.read_csv(\"../data/processed/final_features.csv\", parse_dates=[\"datetime\"])\n",
    "\n",
    "print(df.shape)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {},
   "source": [
    "## 🧪 1. Data Splitting\n",
    "\n",
    "### 📅 1.1 Train/Test Split\n",
    "\n",
    "As this is a time series forecasting task, we use a **chronological split** rather than a random one.\n",
    "\n",
    "We train on data before 2018 and test on data from 2018 onward.\n",
    "\n",
    "---\n",
    "\n",
    "#### 📆 Code: Temporal split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Temporal split\n",
    "cutoff = \"2018-01-01\"\n",
    "\n",
    "train = df[df[\"datetime\"] < cutoff].copy()\n",
    "test = df[df[\"datetime\"] >= cutoff].copy()\n",
    "\n",
    "print(f\"Train: {train.shape}, Test: {test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6",
   "metadata": {},
   "source": [
    "#### 🕰️ Why Temporal Split Instead of Random Split?\n",
    "\n",
    "In traditional machine learning tasks, a **random 80/20 split** (using `train_test_split()` from `sklearn`) is commonly used because the data is assumed to be **i.i.d.** (independent and identically distributed).\n",
    "\n",
    "However, in **time series forecasting**, this assumption does **not hold**.\n",
    "\n",
    "Using a random split in this case would mix **past and future data** in both the training and test sets, which can result in:\n",
    "\n",
    "- ❌ Data leakage (seeing future information during training)\n",
    "- ❌ Over-optimistic performance metrics\n",
    "- ❌ Unrealistic deployment expectations\n",
    "\n",
    "Instead, we apply a **chronological split**:\n",
    "- The **training set** contains all data *before 2018*.\n",
    "- The **test set** contains all data *from 2018 onwards*.\n",
    "\n",
    "This better reflects a real-world scenario where we aim to predict **future energy consumption** using **historical data only**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {},
   "source": [
    "## ⚙️ 2. Baseline Models\n",
    "\n",
    "Before jumping into complex machine learning models, it's important to establish **baseline models**. These help set a reference for evaluating the performance of more advanced approaches.\n",
    "\n",
    "We implement two simple yet meaningful baselines:\n",
    "\n",
    "### 🐢 2.1 Naive Model\n",
    "\n",
    "This model assumes that **the energy load at the current hour is equal to the load one hour ago**:\n",
    "\n",
    "$$\n",
    "\\hat{y}_t = y_{t-1}\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "- $\\hat{y}_t$ is the predicted energy load at time step $t$, and \n",
    "- $\\hat{y}_{t-1}$ is the actual observed load at the previous time step $t-1$\n",
    "\n",
    "This approach is commonly used as a **baseline for time series forecasting** tasks, especially when the data exhibits **high temporal continuity**, such as electricity consumption, which changes gradually over time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8",
   "metadata": {},
   "source": [
    "### 📊 2.2 Mean Model\n",
    "\n",
    "This model predicts the **mean of the training set** for every timestamp in the test set:\n",
    "\n",
    "$$\n",
    "\\hat{y}_t = \\frac{1}{n} \\sum_{i=1}^{n} y_i\n",
    "$$\n",
    "\n",
    "where \n",
    "\n",
    "- $\\hat{y}_t$ is the predicted value for time step $t$\n",
    "- ${y}_{i}$ are the actual observed values in the training set\n",
    "- and $n$ is the number of training samples\n",
    "\n",
    "This model acts as a **constant predictor**, offering a **useful minimum performance threshold**. It’s helpful to understand whether a more complex model provides meaningful improvements beyond simply predicting the average.\n",
    "\n",
    "While simple, it reflects the performance of a constant model and helps identify the **minimum performance threshold**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {},
   "source": [
    "### 📏 Evaluation Metrics\n",
    "\n",
    "We will evaluate these baselines using three standard regression metrics:\n",
    "\n",
    "#### **MAE** – *Mean Absolute Error*\n",
    "$$\n",
    "\\text{MAE} = \\frac{1}{n} \\sum_{i=1}^{n} |{y}_{i} - \\hat{{y}_{i}} |\n",
    "$$\n",
    "- Measures the average absolute difference between predictions and actual values.  \n",
    "- Intuitive to interpret, same unit as the target variable.  \n",
    "- Does **not** penalize large errors more than small ones.\n",
    "\n",
    "#### **RMSE** – *Root Mean Squared Error*\n",
    "$$\n",
    "\\text{RMSE} = \\sqrt{ \\frac{1}{n} \\sum_{i=1}^{n} \\left({y}_{i} - \\hat{{y}_{i}} \\right)^{2}}\n",
    "$$\n",
    "- Similar to MAE, but penalizes **larger errors more heavily**.  \n",
    "- Sensitive to outliers.  \n",
    "- Also in the same unit as the target variable.\n",
    "\n",
    "#### **R²** – *Coefficient of Determination*\n",
    "$$\n",
    "R² = 1 - \\frac{\\sum_{i=1}^{n} \\left({y}_{i} - \\hat{{y}_{i}} \\right)^{2}}{\\sum_{i=1}^{n} \\left({y}_{i} - \\bar{{y}} \\right)^{2}}\n",
    "$$\n",
    "- Evaluates how well the model explains the variance of the target variable.  \n",
    "- R² = 1 → perfect predictions  \n",
    "- R² = 0 → no better than predicting the mean  \n",
    "- R² < 0 → **worse** than the mean model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define target variable\n",
    "target = \"total_load_actual\"\n",
    "\n",
    "# Naive model: use previous hour’s load as prediction\n",
    "naive_preds = test[\"load_lag_1h\"].copy()\n",
    "\n",
    "# Mean model: use mean of training target for all test predictions\n",
    "mean_value = train[target].mean()\n",
    "mean_preds = [mean_value] * len(test)\n",
    "\n",
    "# Actual values\n",
    "y_true = test[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Metrics for both models\n",
    "\n",
    "\n",
    "def evaluate_model(y_true, y_pred, name):\n",
    "    mae = mean_absolute_error(y_true, y_pred)\n",
    "    rmse = mean_squared_error(y_true, y_pred)\n",
    "    r2 = r2_score(y_true, y_pred)\n",
    "    print(f\"{name} → MAE: {mae:.2f} | RMSE: {rmse:.2f} | R²: {r2:.4f}\")\n",
    "\n",
    "\n",
    "evaluate_model(y_true, naive_preds, \"Naive Model\")\n",
    "evaluate_model(y_true, mean_preds, \"Mean Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualización: comparar modelos vs real\n",
    "plt.figure(figsize=(15, 5))\n",
    "plt.plot(\n",
    "    test[\"datetime\"][:168], y_true[:168], label=\"Actual\", color=\"black\", linewidth=2\n",
    ")\n",
    "plt.plot(test[\"datetime\"][:168], naive_preds[:168], label=\"Naive\", linestyle=\"--\")\n",
    "plt.plot(test[\"datetime\"][:168], mean_preds[:168], label=\"Mean\", linestyle=\":\")\n",
    "plt.title(\"Energy Load Forecast: Naive vs Mean vs Actual (First 7 days of test)\")\n",
    "plt.ylabel(\"Load (MW)\")\n",
    "plt.xlabel(\"Time\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13",
   "metadata": {},
   "source": [
    "### 📉 Result Analysis: Why is R² Negative for the Mean Model?\n",
    "\n",
    "While the Mean Model appears simple and intuitive, its performance in time series tasks is often very poor.\n",
    "\n",
    "- It predicts a constant value (the mean of the training set) for all test timestamps.\n",
    "- This completely ignores time-related patterns such as seasonality, trends, or cycles.\n",
    "- As a result, its predictions deviate significantly from the true values.\n",
    "\n",
    "This is reflected in a **negative R²**, which indicates that the model performs worse than simply predicting the average of the test labels (a horizontal line).\n",
    "\n",
    "By contrast, the **Naive Model**, which uses the value from the previous hour, leverages the natural continuity in the data — especially useful in energy demand prediction — and achieves a much higher R².\n",
    "\n",
    "📌 **Conclusion**:  \n",
    "The poor performance of the Mean Model highlights the importance of incorporating temporal dynamics in forecasting models."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prediction-temporal-series-p2enJBmg-py3.13",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
